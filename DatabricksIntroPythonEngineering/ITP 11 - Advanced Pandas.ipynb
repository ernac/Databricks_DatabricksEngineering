{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0e53b44-119d-41a4-a9f8-d8b7c5b77115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "982f84be-6a4f-4329-9821-9384287eeb03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Advanced Pandas\n",
    "\n",
    "<!-- ## ![Spark Logo Tiny](https://files.training.databricks.com/images/105/logo_spark_tiny.png)  -->\n",
    "\n",
    "In this lesson you:\n",
    "* Explore some more advanced features pandas provides including:\n",
    "  - Renaming columns\n",
    "  - Filtering the DataFrame\n",
    "  - Grouping and aggregation Functions\n",
    "  - Sorting\n",
    "  - Imputing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2ba70ba-a30b-48e9-b974-2a37d4d5a9bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "Follow these steps to select the classic compute cluster:\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "    - In the drop-down, select **More**.\n",
    "    - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d93ce2e6-34d2-442a-9a0f-7101016b0198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "For this lesson, we are going to work with datasets. Running the cell below will define and give us access to variables defining the path to our datasets in the Databricks File System."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "017783b4-4966-4bd4-8cf1-99066bcc9764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01e6e8dd-14bd-471a-a404-9bfa9dc4e6bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Remember, to access **`pandas`** functionality, we must **`import`** the library first. We do not have to **`pip install pandas`** because we already have it installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c90b74f0-5041-42ef-8679-a4e3c965587d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5a4c87a-421a-461d-9d48-2893d14291eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Reading Data\n",
    "\n",
    "<!-- <img src=\"https://files.training.databricks.com/images/301/sf.jpg\" style=\"height: 200px; margin: 10px; border: 1px solid #ddd; padding: 10px\"/> -->\n",
    "\n",
    "So far we have created a DataFrame by manually specifying the rows and columns. Often, we will have a dataset stored as a CSV (comma-separated-value) file. \n",
    "\n",
    "**`pandas`** provides a function called [**read_csv(path)**](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html), where we provide a path to where our CSV file is stored, and it returns a DataFrame of the contents at that path.\n",
    "\n",
    "You'll be analyzing data from <a href=\"http://insideairbnb.com/get-the-data.html\" target=\"_blank\">Inside Airbnb</a> to better understand the San Francisco rental market. Let's read in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a32dd118-f656-4c20-a05f-b8901481241b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = f\"{DA.paths.datasets}/sf-airbnb/sf-airbnb.csv\".replace(\"dbfs:\", \"/dbfs\")\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9d9177e4-d513-4923-b833-2ce4d33c42f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "To look at the first few records of the dataset, we can call [**head()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html). If you do not specify the number of rows, it defaults to 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bc5236c-0816-4187-ace7-469df7d48660",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0f0f1cb-319b-4243-85e0-dbe20fe6ba31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Conversely, we can call [**tail()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html) to look at the last few records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "305373dd-6103-4962-94dc-4e75c6408c49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c8e260-66bf-4d43-b35b-00a942c75633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Renaming Columns\n",
    "\n",
    "We can rename columns of our DataFrame using [**rename()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html). We pass into columns a dictionary containing the mappings from the old column names to the new ones to the **`columns`** parameter.\n",
    "\n",
    "Let's rename the **`neighbourhood`** column above to be **`neighborhood`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7ce77ce-91cb-4dfc-80e0-548f39cbbf7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"neighbourhood\": \"neighborhood\"})\n",
    "df[[\"id\", \"neighborhood\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da57a4af-c504-4784-9308-ae51a11ddd3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Filtering\n",
    "\n",
    "Often, you will want to select a subset of rows that meet a certain criteria, which can be accomplished by specifying: **`df[bool_array]`**, where **`bool_array`** is a **`Series`** of **`True`** and **`False`** values for each row. \n",
    "\n",
    "The rows that evaluate to **`True`** are kept, while the ones that evaluate to **`False`** are not. \n",
    "\n",
    "Let's filter for all the rows **`host_is_superhost`** is **`\"t\"`**, meaning the airbnb owner is a superhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "966d2e8d-de79-407a-853a-38ab276fdfc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = df[df[\"host_is_superhost\"] == \"t\"]\n",
    "filtered_df[[\"id\", \"host_is_superhost\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "300e01e3-2c02-428a-bc79-b55da45cf3d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here, **`df[\"host_is_superhost\"] == \"t\"]`** is our boolean array. Let's take a look at the corresponding **True/False** row indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c6d6cd3-47d8-46fa-b1bb-d3ef3e908a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"host_is_superhost\"] == \"t\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c064f613-d174-4c38-8b72-d8e38f376157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can also search for all the records where the **`host_is_superhost`** is NOT \"t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e430cee-7f30-48fd-8517-def7d88ffaa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"host_is_superhost\"] != \"t\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45149697-b53d-4090-b01a-6f955601fde9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pandas Boolean Operators\n",
    "\n",
    "Often you will want to evaluate multiple criteria to filter out records. For example, let's select all records where the host is a superhost and the airbnb has at least 150 reviews.\n",
    "\n",
    "Instead of the normal Boolean operators we have seen previously, we have [bitwise Boolean operators](https://www.w3schools.com/python/gloss_python_bitwise_operators.asp):\n",
    "* **`and`** -> **`&`**\n",
    "* **`or`** -> **`|`** \n",
    "* **`not`** -> **`~`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43216fb1-4a32-4d45-abbb-fd8b58ba66e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = df[(df[\"host_is_superhost\"] == \"t\") & (df[\"number_of_reviews\"] >= 150)]\n",
    "filtered_df[[\"id\", \"host_is_superhost\", \"number_of_reviews\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70b1b580-2f5d-44f7-8bb9-8dc900857ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Aggregate Functions\n",
    "\n",
    "Aggregate functions are functions that take in a series of inputs and return a single output. \n",
    "\n",
    "The most common ones that we use in pandas are ones that take in numerical **`Series`** and return a statistic of interest, such as the mean. \n",
    "\n",
    "Let's take a look at the mean, min, and max of **`number_of_reviews`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d7d6deb-a7de-4442-b491-0754abefa7ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(df[\"number_of_reviews\"].mean())\n",
    "print(df[\"number_of_reviews\"].min())\n",
    "print(df[\"number_of_reviews\"].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80438462-1602-4a89-a551-43efbbd0314e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Another useful method is [**describe()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) which provides a report of summary statistics on a given numerical **`Series`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe38b47e-24ad-4821-855b-5b07d65472ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"number_of_reviews\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbf2e42d-459c-46ee-bc63-832acb65541e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can also use this method on a DataFrame to see it applied to every numerical column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eab6c69d-c9d2-4e0e-9636-f2debfe29bb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[[\"number_of_reviews\", \"host_listings_count\", \"bedrooms\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b57c3275-8f58-4113-899d-afb099d49261",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Many times, you won't care about the 6th value after the decimal. Let's round our results by calling [**round()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.round.html?highlight=round#pandas.DataFrame.round)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aca5b0a3-880a-48c5-883a-4d5fb4eeaa0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[[\"number_of_reviews\", \"host_listings_count\", \"bedrooms\"]].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "354e4d7c-3e2d-4ea1-a29e-f46d694c6872",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Group By\n",
    "\n",
    "Sometimes we will want to see the results of an aggregate function per category in a non-numerical column. \n",
    "\n",
    "For example, say we wanted to see the average number of bedrooms per neighborhood.\n",
    "\n",
    "In order to do this we first use the [**groupby([columns])**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) method and specify the category we want to group by. In this case, let's group by **`neighborhood`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e77c0f8-48d5-470b-8b0b-9c17810b9cce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.groupby([\"neighborhood\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6212434-3eea-42ac-bb1e-189915a13e71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Then we apply the aggregate function of interest. In this case, **`mean()`** to the column of interest, in this case **`bedrooms`**.\n",
    "\n",
    "**Note:** Here we use **`[[\"bedrooms\"]]`** to select for bedrooms because we could add other columns in addition to bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7899c74-56e8-4051-a6f4-64c80bf51342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grouped_df = df.groupby([\"neighborhood\"])[[\"bedrooms\"]].mean().head(10)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b845703-0883-4558-aad6-dab6e07a9c5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Reset Index\n",
    "\n",
    "DataFrames always have some sort of index, which we've seen displayed as the leftmost column in the examples above. By default, they are numbers, but many operations can change those indices to something else. In the example above, **`neighborhood`** became the index rather than a column. We can see that if we print out the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35aa1366-f861-4154-81d4-59bbb4f69df0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grouped_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5e81e8b-0bbf-4b46-8670-2909f33831f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Sometimes, resetting the index back to its default integer sequence is desirable. Some cases where this might be useful include:\n",
    "* Eliminating duplicates in the current index\n",
    "* Transforming the current index into a column so that you can include those values in columnar computations or transformations\n",
    "* Making the index consistent and contiguous following an operation that altered the DataFrames shape or structure\n",
    " \n",
    "To reset the index, use [**reset_index()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615fa0f7-327d-49e6-a92c-fe6b55d6bfad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "reset_df = grouped_df.reset_index()\n",
    "reset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec514131-c00d-40a4-87a8-a58e8979e5fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " \n",
    "## Sorting\n",
    "\n",
    "Pandas provides a [**sort_values()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html) method to sort the rows in a **`DataFrame`** or **`Series`**.\n",
    "\n",
    "If called on a **`DataFrame`** you need to specify which column you are sorting by like this **`df.sort_values([col])`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49468acd-d17f-4595-9865-5ae593bb6085",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sorted_df = df.sort_values([\"bedrooms\"])\n",
    "sorted_df[[\"id\",\"bedrooms\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4601b768-a053-4f5b-b8ed-8d2262cd0b3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "If applied to a **`Series`** there is only one column, so you don't need to specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50804330-030d-42d3-8e22-935495f8e531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"bedrooms\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e6286b7-dc08-424f-9c6e-71224eb8c509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "By default **`sort_values()`** sorts in ascending order. You can specify the **`ascending=False`** parameter to change it to descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b997bb5-c88a-419f-bf88-b09c8e77e161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"bedrooms\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c463172-8842-4dc6-9dab-4681cc921015",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " \n",
    "# NaN \n",
    "\n",
    "You might have noticed that our **`DataFrame`** contains NaN values. These indicate a missing value. \n",
    "\n",
    "We have a few ways we can handle missing values. Often having these values present causes problems for computational tasks.\n",
    "\n",
    "First, we can check using the [**isna()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna) method, alias for [**isnull()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html#pandas.DataFrame.isnull), and the **`sum()`** method to count the number of NaN values present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "058ffdc5-e0f7-4cee-9fd9-a72757ac84be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nan_df = df[[\"security_deposit\", \"notes\"]] # subset of columns with NaNs\n",
    "nan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd2c8255-f542-4279-8c24-724e698427ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nan_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd8982d0-80b7-4407-a948-897586ee9ca3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dropping NaN\n",
    "\n",
    "One way you can handle NaN is to drop all rows that have NaN values. We can use the [**dropna()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html) method to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbf2d444-da9e-4ed3-98a4-ec44985eea39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nan_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc6d2bd7-3a57-4a20-81b0-0152863cd939",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Impute Columns\n",
    "\n",
    "However, we are throwing away a lot of information when we drop records - in the example above, we removed over 3000 rows.\n",
    "\n",
    "Instead of dropping rows with missing values, we can impute the missing values using [**fillna()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) and specifying a default value to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34c7fbd7-ca03-4246-83ab-1b6a9b351b67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nan_df.fillna(\"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5cccad3-501c-4f3a-b3a7-15822e02e816",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Oftentimes, we want to impute different values to different columns. For example, with `numeric` values, we can impute with the mean/median/etc. For `categorical` features, imputing with the mode or a special category are common.\n",
    "\n",
    "Let's instead specify that **`security_deposit`** is `$0.00` if it is missing. We can pass in a dictionary to **`fillna()`** that has column names as the key and the value to impute the column with as the value. \n",
    "\n",
    "You can optionally specify **`inplace=True`** if you want to update the underlying DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aa6bd8e-fd3f-456d-8879-dbb0ab572bc2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nan_df.fillna({\"security_deposit\": \"$0.00\", \"notes\": \"Missing\"}, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cffabab-c343-48bd-a3e3-fd5f4ac54467",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " \n",
    "## Write to CSV\n",
    "\n",
    "We can write a **`pandas`** DataFrame to a CSV file as shown below using the [**to_csv()**](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9313f3c7-df08-4f0f-ae36-c4e0b2e50bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = DA.paths.working_dir.replace(\"dbfs:\", \"/dbfs\") + \".csv\"\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d988ca2f-4820-4b28-9ed9-daf0370a3764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " \n",
    "We can then read our csv file back in with **`read_csv`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f5ac8cc-bbe9-4cdc-b9b8-740faf1bc59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_df = pd.read_csv(file_path)\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a266ddd-8f32-4a0e-a252-87f6ece4ddcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2025 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "ITP 11 - Advanced Pandas",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}